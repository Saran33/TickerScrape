{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerizer import numerize as rev_numerize\n",
    "from numerize.numerize import numerize\n",
    "# import locale\n",
    "# locale.setlocale(locale.LC_ALL, 'en_US')  # Use '' for auto, or force e.g. to 'en_US.UTF-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flz = 'N/A'\n",
    "\n",
    "def to_float(float_str):\n",
    "    try:\n",
    "        fl = float(float_str)\n",
    "    except:\n",
    "        fl = float(\"NaN\")\n",
    "    return fl\n",
    "\n",
    "to_float(flz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = numerize(2460000000)\n",
    "print(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_str = '$2.46T'\n",
    "cur_str = '$2.46 Trillion'\n",
    "\n",
    "num_strs = ['thousand', 'million', 'billion', 'trillion']\n",
    "for x in num_strs:\n",
    "    if x in cur_str.lower():\n",
    "        str_num_1 = cur_str.lower().replace(x, '').replace(',','').replace('$','')\n",
    "# str_num_1 = [cur_str.replace(x, '') for x in num_strs if x in cur_str.lower()]\n",
    "print(str_num_1)\n",
    "if str_num_1 == cur_str:\n",
    "    str_num_1 = cur_str.replace('M', '').replace('B', '').replace('T', '').replace(',','').replace('$','')\n",
    "print (str_num_1)\n",
    "if 'm' in cur_str.lower():\n",
    "    fl_num = float(str_num_1) * 1000000\n",
    "elif 'b' in cur_str.lower():\n",
    "    fl_num = float(str_num_1) * 1000000000\n",
    "elif 'thousand' in cur_str.lower():\n",
    "    fl_num = float(str_num_1) * 1000\n",
    "elif ('T' in cur_str) or ('trillion' in cur_str.lower()):\n",
    "    fl_num = float(str_num_1) * 1000000000000\n",
    "print (\"${0:,.2f}\".format(fl_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_fl = '$' + numerize(fl_num, 2)\n",
    "print (cur_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cur_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curr_str_to_float(cur_str, symbol='$'):\n",
    "    '''Convert a currency string-formatted number into a float.'''\n",
    "\n",
    "    num_strs = ['thousand', 'million', 'billion', 'trillion']\n",
    "    for x in num_strs:\n",
    "        if x in cur_str.lower():\n",
    "            str_num_1 = cur_str.lower().replace(x, '').replace(',','').replace(symbol,'')\n",
    "            # str_num_1 = [cur_str.replace(x, '') for x in num_strs if x in cur_str.lower()]\n",
    "            if str_num_1 == cur_str:\n",
    "                str_num_1 = cur_str.replace('M', '').replace('B', '').replace('T', '').replace(',','').replace(symbol,'')\n",
    "            if 'm' in cur_str.lower():\n",
    "                fl_num = float(str_num_1) * 1000000\n",
    "            elif 'b' in cur_str.lower():\n",
    "                fl_num = float(str_num_1) * 1000000000\n",
    "            elif 'thousand' in cur_str.lower():\n",
    "                fl_num = float(str_num_1) * 1000\n",
    "            elif ('T' in cur_str) or ('trillion' in cur_str.lower()):\n",
    "                fl_num = float(str_num_1) * 1000000000000\n",
    "            # print (\"${0:,.2f}\".format(fl_num))\n",
    "        else:\n",
    "            fl_num = cur_str\n",
    "    return fl_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curr_str_to_float(cur_str, symbol='$'):\n",
    "    '''Convert a currency string-formatted number into a float.'''\n",
    "\n",
    "    num_strs = ['thousand', 'million', 'billion', 'trillion']\n",
    "    str_num_1 = None\n",
    "    try:\n",
    "        for x in num_strs:\n",
    "            if x in cur_str.lower():\n",
    "                str_num_1 = cur_str.lower().replace(x, '').replace(',','').replace(symbol,'')\n",
    "                # str_num_1 = [cur_str.replace(x, '') for x in num_strs if x in cur_str.lower()]\n",
    "        if not str_num_1:\n",
    "            str_num_1 = cur_str.replace('M', '').replace('B', '').replace('T', '').replace(',','').replace(symbol,'')\n",
    "        if 'm' in cur_str.lower():\n",
    "            fl_num = float(str_num_1) * 1000000\n",
    "        elif 'b' in cur_str.lower():\n",
    "            fl_num = float(str_num_1) * 1000000000\n",
    "        elif 'thousand' in cur_str.lower():\n",
    "            fl_num = float(str_num_1) * 1000\n",
    "        elif ('T' in cur_str) or ('trillion' in cur_str.lower()):\n",
    "            fl_num = float(str_num_1) * 1000000000000\n",
    "        else:\n",
    "            fl_num = float(\"NaN\")\n",
    "        # print (\"${0:,.2f}\".format(fl_num))\n",
    "    except:\n",
    "        fl_num = float(\"NaN\")\n",
    "        print (fl_num)\n",
    "    return fl_num\n",
    "\n",
    "def curr_str_to_int(cur_str, symbol='$'):\n",
    "    '''Convert a currency string-formatted number into a float.'''\n",
    "\n",
    "    num_strs = ['thousand', 'million', 'billion', 'trillion']\n",
    "    str_num_1 = None\n",
    "    try:\n",
    "        for x in num_strs:\n",
    "            if x in cur_str.lower():\n",
    "                str_num_1 = cur_str.lower().replace(x, '').replace(',','').replace(symbol,'')\n",
    "                # str_num_1 = [cur_str.replace(x, '') for x in num_strs if x in cur_str.lower()]\n",
    "        if not str_num_1:\n",
    "            str_num_1 = cur_str.replace('M', '').replace('B', '').replace('T', '').replace(',','').replace(symbol,'')\n",
    "        if 'm' in cur_str.lower():\n",
    "            fl_num = float(str_num_1) * 1000000\n",
    "        elif 'b' in cur_str.lower():\n",
    "            fl_num = float(str_num_1) * 1000000000\n",
    "        elif 'thousand' in cur_str.lower():\n",
    "            fl_num = float(str_num_1) * 1000\n",
    "        elif ('T' in cur_str) or ('trillion' in cur_str.lower()):\n",
    "            fl_num = float(str_num_1) * 1000000000000\n",
    "        else:\n",
    "            fl_num = None\n",
    "        # print (\"${0:,.2f}\".format(fl_num))\n",
    "    except:\n",
    "        fl_num = None\n",
    "        print (fl_num)\n",
    "    return fl_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# cur_str = '2.46 Trillion'\n",
    "# cur_str = '7.59M'\n",
    "cur_str = 'N/A'\n",
    "\n",
    "fl_num = curr_str_to_float(cur_str, symbol='$')\n",
    "print (\"{0:,.2f}\".format(fl_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7590000.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_str = '$7.59M'\n",
    "\n",
    "curr_str_to_int(cur_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_codes = pd.read_csv('csv_files/ISO_4217_FX_Codes.csv')\n",
    "fx_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fx_codes['Entity'][:270] = fx_codes['Entity'][:270].str.lower().str.title()\n",
    "# fx_codes['Entity'][:270] = fx_codes['Entity'][:270].str.replace('Of', 'of').str.replace('And ', 'and ')\n",
    "# fx_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fx_codes.tail(20)\n",
    "# fx_codes = fx_codes.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fx_codes.to_csv('csv_files/ISO_4217_FX_Codes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_codes.tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'United States'\n",
    "\n",
    "entity = fx_codes.loc[fx_codes['Entity'].str.contains(country, regex=False)]\n",
    "entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in entity.iterrows():\n",
    "    # print (index)\n",
    "    new_currency = entity['Currency'][index]\n",
    "    print (new_currency)\n",
    "    new_ticker = entity['Ticker'][index]\n",
    "    print (new_ticker)\n",
    "    ISO_4217 = entity['ISO_4217'][index]\n",
    "    print (ISO_4217)\n",
    "    minor_unit = entity['Minor unit'][index]\n",
    "    print (minor_unit)\n",
    "    fund = entity['Fund'][index]\n",
    "    print (fund)\n",
    "    description = entity['Description'][index]\n",
    "    print (description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv('csv_files/All_countries.csv')\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa = pd.read_csv('csv_files/Africa.csv')\n",
    "africa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asia = pd.read_csv('csv_files/Asia.csv')\n",
    "asia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europe = pd.read_csv('csv_files/Europe.csv')\n",
    "europe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_america = pd.read_csv('csv_files/North_America.csv')\n",
    "north_america.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oceania = pd.read_csv('csv_files/Oceania.csv')\n",
    "oceania.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "south_america = pd.read_csv('csv_files/South_America.csv')\n",
    "south_america.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "North_American_territories = pd.read_csv('csv_files/North_American_territories.csv')\n",
    "North_American_territories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Oceania_territories = pd.read_csv('csv_files/Oceania_territories.csv')\n",
    "Oceania_territories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "South_American_territories = pd.read_csv('csv_files/South_American_territories.csv')\n",
    "South_American_territories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['Continent'] = np.where(countries['Country'].isin(africa['Country']), 'Africa', '')\n",
    "countries['Continent'] = np.where(countries['Country'].isin(asia['Country']), 'Asia', countries['Continent'])\n",
    "countries['Continent'] = np.where(countries['Country'].isin(europe['Country']), 'Europe', countries['Continent'])\n",
    "countries['Continent'] = np.where(countries['Country'].isin(north_america['Country']), 'North America', countries['Continent'])\n",
    "countries['Continent'] = np.where(countries['Country'].isin(south_america['Country']), 'South America', countries['Continent'])\n",
    "countries['Continent'] = np.where(countries['Country'].isin(North_American_territories['Territory']), 'North America', countries['Continent'])\n",
    "countries['Continent'] = np.where(countries['Country'].isin(South_American_territories['Territory']), 'South America', countries['Continent'])\n",
    "countries['Continent'] = np.where(countries['Country'].isin(Oceania_territories['Territory']), 'Oceania', countries['Continent'])\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['Continent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries.to_csv('csv_files/Country_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv('csv_files/Country_data.csv')\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in North_American_territories.iterrows():\n",
    "    countries['Territory'] = np.where(countries['Country'].str.contains(North_American_territories['Territory'][index]), True, False)\n",
    "    countries['Territory_of'] = np.where(countries['Country'].str.contains(North_American_territories['Territory'][index]), North_American_territories['Country'][index], '')\n",
    "countries['Territory'] = np.where(countries['Country'].isin(North_American_territories['Territory']), True, False)\n",
    "countries['Territory_of'] = np.where(countries['Country'].isin(North_American_territories['Territory']), North_American_territories['Country'][index], countries['Territory_of'])\n",
    "\n",
    "countries['Territory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in South_American_territories.iterrows():\n",
    "    countries['Territory'] = np.where(countries['Country'].str.contains(South_American_territories['Territory'][index]), True, countries['Territory'])\n",
    "    countries['Territory_of'] = np.where(countries['Country'].str.contains(South_American_territories['Territory'][index]), South_American_territories['Country'][index], '')\n",
    "countries['Territory'] = np.where(countries['Country'].isin(South_American_territories['Territory']), True, countries['Territory'])\n",
    "countries['Territory_of'] = np.where(countries['Country'].isin(South_American_territories['Territory']), South_American_territories['Country'][index], countries['Territory_of'])\n",
    "\n",
    "countries['Territory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in Oceania_territories.iterrows():\n",
    "    countries['Territory'] = np.where(countries['Country'].str.contains(Oceania_territories['Territory'][index]), True, countries['Territory'])\n",
    "    countries['Territory_of'] = np.where(countries['Country'].str.contains(Oceania_territories['Territory'][index]), Oceania_territories['Country'][index], '')\n",
    "countries['Territory'] = np.where(countries['Country'].isin(Oceania_territories['Territory']), True, countries['Territory'])\n",
    "countries['Territory_of'] = np.where(countries['Country'].isin(Oceania_territories['Territory']), Oceania_territories['Country'][index], countries['Territory_of'])\n",
    "\n",
    "countries['Territory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = pd.read_csv('csv_files/regions.csv')\n",
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['Region'] = np.where(countries['ISO_3166'].isin(regions['ISO_3166']), regions['Region'], '')\n",
    "countries\n",
    "# countries['Region'].value_counts()\n",
    "# countries.loc[countries['Region'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu = pd.read_csv('csv_files/EU.csv')\n",
    "eu.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asean = pd.read_csv('csv_files/ASEAN.csv')\n",
    "asean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g10 = pd.read_csv('csv_files/G10_countries.csv')\n",
    "g10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g20 = pd.read_csv('csv_files/G20_countries.csv')\n",
    "g20 = g20.drop_duplicates()\n",
    "print (g20.count())\n",
    "g20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = pd.read_csv('csv_files/EM_countries.csv')\n",
    "em.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv('csv_files/Country_data.csv')\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in eu.iterrows():\n",
    "    countries['Econ_Group'] = np.where(countries['Country'].str.contains(eu['Country'][index]), 'EU', '')\n",
    "\n",
    "countries['Econ_Group'] = np.where(countries['Country'].isin(eu['Country']), 'EU', countries['Econ_Group'])\n",
    "countries['Econ_Group'].value_counts()\n",
    "# countries.loc[countries['Econ_Group'] == 'EU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in asean.iterrows():\n",
    "    countries['Econ_Group'] = np.where(countries['Country'].str.contains(asean['Country'][index]), 'ASEAN', countries['Econ_Group'])\n",
    "\n",
    "countries['Econ_Group'] = np.where(countries['Country'].isin(asean['Country']), 'ASEAN', countries['Econ_Group'])\n",
    "print(countries['Econ_Group'].value_counts())\n",
    "countries.loc[countries['Econ_Group'] == 'ASEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(countries['Econ_Group'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in g10.iterrows():\n",
    "    countries['G10'] = np.where(countries['Country'].str.contains(g10['Country'][index]), True, False)\n",
    "\n",
    "countries['G10'] = np.where(countries['Country'].isin(g10['Country']), True, countries['G10'])\n",
    "\n",
    "countries['G10'] = np.where(countries['Country'].astype(str) == 'United States Minor Outlying Islands', False, countries['G10'])\n",
    "print(countries['G10'].value_counts())\n",
    "countries.loc[countries['G10'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in g20.iterrows():\n",
    "    countries['G20'] = np.where(countries['Country'].str.contains(g20['Country'][index]), True, False)\n",
    "\n",
    "countries['G20'] = np.where(countries['Country'].isin(g20['Country']), True, countries['G20'])\n",
    "\n",
    "countries['G20'] = np.where(countries['Country'].astype(str) == 'United States Minor Outlying Islands', False, countries['G20'])\n",
    "print(countries['G20'].value_counts())\n",
    "# countries.loc[countries['G20'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv('csv_files/Country_data.csv')\n",
    "countries = countries.iloc[:,:9]\n",
    "countries\n",
    "\n",
    "em = pd.read_csv('csv_files/EM_countries.csv')\n",
    "em.tail()\n",
    "\n",
    "em_categories = []\n",
    "for col in em.columns:\n",
    "    em_categories.append(col)\n",
    "em_categories\n",
    "\n",
    "for cat in em_categories:\n",
    "    countries[cat] = False\n",
    "    for index, value in em[cat].iteritems():\n",
    "        for c_index, c_value in countries.iterrows():\n",
    "            # countries['IMF EM_1'][c_index] = np.where(countries['Country'][c_index].__contains__(em['IMF EM'][index]), True, countries['IMF EM_1'][c_index])\n",
    "            countries[cat][c_index] = np.where(countries['Country'][c_index].split(',')[0] in (em[cat][index]), True, countries[cat][c_index])\n",
    "\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc[countries['Country'] == 'Niger', 'BRICS & Next Eleven'] = countries.loc[countries['Country'] == 'Niger', 'BRICS & Next Eleven'].replace(True, False)\n",
    "countries.loc[countries['Country'] == 'Niger', 'EM Bond Index'] = countries.loc[countries['Country'] == 'Niger', 'EM Bond Index'].replace(True, False)\n",
    "countries.loc[countries['Country'] == 'Niger', 'Cornell University EMI E20'] = countries.loc[countries['Country'] == 'Niger', 'Cornell University EMI E20'].replace(True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in em_categories:\n",
    "    print(countries[cat].value_counts())\n",
    "    countries.loc[countries[cat] == True]\n",
    "\n",
    "for cat in em_categories:\n",
    "    print(em[cat].replace(r'^\\s*$', np.nan, regex=True).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries.loc[countries['BRICS & Next Eleven'] == True]\n",
    "# countries.loc[countries['EM Bond Index'] == True]\n",
    "# countries.loc[countries['Cornell University EMI E20'] == True]\n",
    "\n",
    "# countries.to_csv('csv_files/Country_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ast import literal_eval\n",
    "# literal_eval('[1.23, 2.34]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries.to_csv('csv_files/Country_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv('csv_files/Country_data.csv')\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['G10', 'G20']:\n",
    "    em_categories.append(i)\n",
    "em_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['Geopol_group'] = \"\"\n",
    "for index, row in countries.iterrows():\n",
    "    # countries['Geopol_group'][index] = []\n",
    "    # for label, content in countries.items():\n",
    "    for col in countries[em_categories]:\n",
    "        colserObj = countries[col]\n",
    "        countries[f'{col}_1'] = np.where(colserObj.values == True, col, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.iloc[100:,20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['Geopol_group'] = countries[countries.columns[20:]].apply(lambda x: ','.join(x.dropna().astype(str)), axis=1)\n",
    "countries['Geopol_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_categories_1 = []\n",
    "for col in countries[em_categories]:\n",
    "    em_categories_1.append(f'{col}_1')\n",
    "em_categories_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_1 = countries.drop(columns=em_categories).drop(columns=em_categories_1)\n",
    "countries_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_1['Geopol_group'] = countries_1['Geopol_group'].str.strip(',').str.replace(',,,,,,,', ',').str.replace(',,,,,,', ',').str.replace(',,,,,', ',').str.replace(',,,,', ',').str.replace(',,,', ',').str.replace(',,', ',')\n",
    "countries_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries_1['Geopol_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries_1.to_csv('csv_files/country_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df = pd.read_csv('csv_files/country_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO_3166</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Territory</th>\n",
       "      <th>Territory_of</th>\n",
       "      <th>Region</th>\n",
       "      <th>Econ_Group</th>\n",
       "      <th>Geopol_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Russia</td>\n",
       "      <td>RU</td>\n",
       "      <td>Europe</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMF EM,BRICS &amp; Next Eleven,FTSE EM,MSCI EM,S&amp;P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country ISO_3166 Continent  Territory Territory_of Region Econ_Group  \\\n",
       "182  Russia       RU    Europe      False          NaN   EMEA        NaN   \n",
       "\n",
       "                                          Geopol_group  \n",
       "182  IMF EM,BRICS & Next Eleven,FTSE EM,MSCI EM,S&P...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# country = 'U.S.'\n",
    "# country = 'United States'\n",
    "# country = 'Gurmeny'\n",
    "country = 'Russia'\n",
    "# country_index = pd.Series(dtype='object')\n",
    "country_row = pd.Series(dtype='object')\n",
    "country_str = country.replace('.', '')\n",
    "if len(country_str) < 5:\n",
    "    country_row = countries_df.loc[countries_df['ISO_3166'].astype(str) == (country_str)]\n",
    "if len(country_row) == 0:\n",
    "    country_row = countries_df.loc[countries_df['Country'].str.contains(country)]\n",
    "    country_row\n",
    "\n",
    "country_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.datacamp.com/community/tutorials/fuzzy-string-python\n",
    "\n",
    "if len(country_row) > 1:\n",
    "    # Ratios = process.extract(country,country_row['Country'])\n",
    "    # print(Ratios)\n",
    "    highest = process.extractOne(country,country_row['Country'])\n",
    "    # print(highest)\n",
    "    country_row = country_row.loc[country_row['Country'].str.contains(highest[0])]\n",
    "country_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(country_row) == 0:\n",
    "    # highest = process.extractOne(country,countries_df['Country']) # scorer=fuzz.token_set_ratio\n",
    "    highest = process.extractOne(country,countries_df['Country'], scorer=fuzz.token_set_ratio)\n",
    "    print(\"WARNING : Using fuzzy logic to predict country:\", highest[0])\n",
    "    country_row = countries_df.loc[countries_df['Country'].str.contains(highest[0])]\n",
    "country_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISO_3166 = country_row['ISO_3166'].values[0]\n",
    "ISO_3166\n",
    "Continent = country_row['Continent'].values[0]\n",
    "Continent\n",
    "Territory = country_row['Territory'].values[0]\n",
    "Territory\n",
    "Territory_of = country_row['Territory_of'].values[0]\n",
    "Territory_of\n",
    "Region = country_row['Region'].values[0]\n",
    "Region\n",
    "Econ_Group = country_row['Econ_Group'].values[0]\n",
    "Econ_Group\n",
    "Geopol_group = country_row['Geopol_group'].values[0]\n",
    "Geopol_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS= pd.read_excel('csv_files/2017_NAICS_Descriptions.xlsx', dtype={'Description': int, 'Title': str, 'Description': str, 'Sector': str})\n",
    "NAICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS['Title'] = NAICS['Title'].str.rstrip().str.rstrip('T')\n",
    "NAICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = NAICS.loc[NAICS['Description'].str.strip().str.startswith('The Sector as a Whole', na=False)]\n",
    "sectors = sectors.drop(columns='Sector')\n",
    "sectors['Description'] = sectors['Description'].str.replace('The Sector as a Whole\\n\\n', '').str.strip()\n",
    "sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sectors.to_csv('csv_files/NAICS17_sectors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_desc = pd.read_excel('csv_files/2017_NAICS_Index_File.xlsx')\n",
    "NAICS_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_descs = NAICS.loc[NAICS['Description'].str.strip().str.startswith('See industry description for', na=False)].copy()\n",
    "no_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_descs['desc_code'] = no_descs['Description'].astype(str).apply(lambda x: re.findall(r'\\d+', x))\n",
    "no_descs['desc_code'] = no_descs['desc_code'].str[0]\n",
    "no_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_desc = NAICS_desc.groupby(['NAICS17'])['INDEX ITEM DESCRIPTION'].apply(','.join).reset_index()\n",
    "NAICS_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_desc = NAICS_desc.loc[NAICS_desc['NAICS17'] != '******']\n",
    "NAICS_desc = NAICS_desc.rename(columns= {'NAICS17': 'desc_code'})\n",
    "NAICS_desc['INDEX ITEM DESCRIPTION'] = NAICS_desc['INDEX ITEM DESCRIPTION'].astype(str)\n",
    "NAICS_desc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_descs.reset_index(inplace=True, drop=True)\n",
    "# no_descs = no_descs.drop(columns = ['level_0', 'index'])\n",
    "no_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_descs['desc_code'] = no_descs['desc_code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = no_descs.merge(NAICS_desc, how='left', left_on='desc_code', right_on='desc_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns='Description')\n",
    "merged_df = merged_df.rename(columns={'INDEX ITEM DESCRIPTION': 'Description'})\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industries = NAICS.loc[~NAICS['Description'].str.strip().str.startswith('The Sector as a Whole', na=False)]\n",
    "industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_industries = industries.merge(merged_df, how='left', left_on=['Code', 'Title', 'Sector'], right_on=['Code', 'Title', 'Sector'])\n",
    "merged_industries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(merged_industries['Description_y'][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_industries['Description'] = \"\"\n",
    "for index, value in merged_industries['Description_y'].iteritems():\n",
    "    merged_industries['Description'][index] = np.where(type(merged_industries['Description_y'][index]) is not type(float), merged_industries['Description_y'][index], merged_industries['Description_x'][index])\n",
    "merged_industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_industries['Description'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in merged_industries['Description_y'].iteritems():\n",
    "    merged_industries['Description'][index] = np.where(merged_industries['Description'][index] == 'nan', merged_industries['Description_x'][index], merged_industries['Description'][index])\n",
    "merged_industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_industries = merged_industries.drop(columns=['Description_x', 'Description_y'])\n",
    "merged_industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = sectors.drop(columns='Description')\n",
    "sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_industries_2 = merged_industries.merge(sectors, how='left', left_on='Sector', right_on='Title')\n",
    "merged_industries_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_industries_2 = merged_industries_2.drop(columns='Title_y')\n",
    "merged_industries_2 = merged_industries_2.rename(columns={'Code_x': 'NAICS_code', 'Title_x': 'Title', 'desc_code': 'NAICS_desc_code', 'Code_y': 'NAICS_sector_code'})\n",
    "merged_industries_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_industries_2.to_csv('csv_files/2017_NAICS_industries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"United States Treasury 3-Year Note 0.250% Apr 15, 2023 (912828ZH65)\"\n",
    "# name = \"U.K. 1 Year Gilt (TMBMKGB-01Y)\"\n",
    "name = \"U.S. 1 Month Treasury Bill (TMUBMUSD01M)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States of America'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "def extract_bond_country(name):\n",
    "    countries_df = pd.read_csv('csv_files/country_dataset.csv')\n",
    "    name_str = name.strip().split()\n",
    "    if name_str[0] == 'U.K.':\n",
    "        country_name = 'United Kingdom'\n",
    "    elif name_str[0] == 'U.S.':\n",
    "        country_name = 'United States of America'\n",
    "    else:\n",
    "        test_str = name_str[0] +' '+ name_str[1]\n",
    "        print(test_str)\n",
    "        highest = process.extractOne(test_str,countries_df['Country'], scorer=fuzz.token_set_ratio)\n",
    "        print(highest[0])\n",
    "        country_name = countries_df.loc[countries_df['Country'].str.contains(highest[0])]['Country'].values[0]\n",
    "    return country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eadf9ca2f0136a17db7d8b7f130ae155eb3ce8fa17d05332ddccc486fc5abac6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('pwepip': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
